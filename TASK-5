%matplotlib inline
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import os
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

vgg = models.vgg19(pretrained=True).features.to(device).eval()
for param in vgg.parameters():
    param.requires_grad = False

content_layers = ['conv_4_2']
style_layers = ['conv_1_1', 'conv_2_1', 'conv_3_1', 'conv_4_1', 'conv_5_1']
def load_image(image_path, size=256, is_synthetic=False):
    transform = transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    if is_synthetic or not os.path.exists(image_path):
        print(f"Image {image_path} not found. Using synthetic data.")
        return torch.rand(1, 3, size, size).to(device)
    try:
        image = Image.open(image_path).convert('RGB')
        return transform(image).unsqueeze(0).to(device)
    except Exception as e:
        print(f"Error loading {image_path}: {e}. Using synthetic data.")
        return torch.rand(1, 3, size, size).to(device)

def gram_matrix(feature):
    b, c, h, w = feature.size()
    features = feature.view(b, c, h * w)
    G = torch.bmm(features, features.transpose(1, 2))
    return G / (c * h * w)

class StyleTransfer:
    def __init__(self, content_img, style_img):
        self.content_img = content_img
        self.style_img = style_img
        self.content_features = self.get_features(content_img)
        self.style_grams = self.get_features(style_img, gram=True)
    
    def get_features(self, img, gram=False):
        features = {}
        x = img
        conv_count = 0
        block = 1
        for idx, layer in enumerate(vgg):
            x = layer(x)
            if isinstance(layer, nn.Conv2d):
                conv_count += 1
                name = f"conv_{block}_{conv_count}"
                if name in (content_layers + style_layers):
                    features[name] = gram_matrix(x) if gram else x
            elif isinstance(layer, nn.ReLU):
                continue
            elif isinstance(layer, nn.MaxPool2d):
                block += 1
                conv_count = 0
        return features

    def compute_loss(self, target_img):
        target_features = self.get_features(target_img)
        content_loss = sum(nn.MSELoss()(target_features[layer], self.content_features[layer])
                           for layer in content_layers)
        style_loss = sum(nn.MSELoss()(gram_matrix(target_features[layer]), self.style_grams[layer])
                         for layer in style_layers)
        return content_loss, style_loss * 5e3

def neural_style_transfer(content_path, style_path, iterations=300, content_weight=1, style_weight=1e6):
    content_img = load_image(content_path, is_synthetic=True)
    style_img = load_image(style_path, is_synthetic=True)
    target_img = content_img.clone().requires_grad_(True).to(device)

    optimizer = optim.Adam([target_img], lr=0.01)
    style_transfer = StyleTransfer(content_img, style_img)

    for i in range(1, iterations + 1):
        optimizer.zero_grad()
        content_loss, style_loss = style_transfer.compute_loss(target_img)
        total_loss = content_weight * content_loss + style_weight * style_loss
        total_loss.backward()
        optimizer.step()
        
        if i % 50 == 0 or i == iterations:
            print(f"Iteration {i}/{iterations}, Content Loss: {content_loss.item():.4f}, Style Loss: {style_loss.item():.4f}")

    return content_img, style_img, target_img

def imshow(img_tensor, title):
    img = img_tensor.clone().detach().cpu().squeeze(0)
    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    img = img + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    img = img.clamp(0, 1).permute(1, 2, 0).numpy()
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

content_path = "./images/content.jpg"
style_path = "./images/style.jpg"
content_img, style_img, stylized_img = neural_style_transfer(content_path, style_path)

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
imshow(content_img, "Content Image")
plt.subplot(1, 3, 2)
imshow(style_img, "Style Image")
plt.subplot(1, 3, 3)
imshow(stylized_img, "Stylized Image")
plt.tight_layout()
plt.show()
